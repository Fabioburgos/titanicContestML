{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad0e3be1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-09T20:18:28.648972Z",
     "iopub.status.busy": "2022-02-09T20:18:28.648321Z",
     "iopub.status.idle": "2022-02-09T20:18:28.656952Z",
     "shell.execute_reply": "2022-02-09T20:18:28.656185Z",
     "shell.execute_reply.started": "2022-02-09T19:19:35.670537Z"
    },
    "papermill": {
     "duration": 0.029168,
     "end_time": "2022-02-09T20:18:28.657171",
     "exception": false,
     "start_time": "2022-02-09T20:18:28.628003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/train.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/gender_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39338081",
   "metadata": {
    "papermill": {
     "duration": 0.007689,
     "end_time": "2022-02-09T20:18:28.674657",
     "exception": false,
     "start_time": "2022-02-09T20:18:28.666968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e378e686",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T20:18:28.696436Z",
     "iopub.status.busy": "2022-02-09T20:18:28.695643Z",
     "iopub.status.idle": "2022-02-09T20:18:28.729228Z",
     "shell.execute_reply": "2022-02-09T20:18:28.728468Z",
     "shell.execute_reply.started": "2022-02-09T19:19:39.989310Z"
    },
    "papermill": {
     "duration": 0.046828,
     "end_time": "2022-02-09T20:18:28.729399",
     "exception": false,
     "start_time": "2022-02-09T20:18:28.682571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Welcome to my notebook about Titanic contest. \n",
    "#First of all, let's save the datasets into variables in order to use it later.\n",
    "train_titanic = pd.read_csv('/kaggle/input/titanic/train.csv')\n",
    "test_titanic = pd.read_csv('/kaggle/input/titanic/test.csv')\n",
    "submission_template = pd.read_csv('/kaggle/input/titanic/gender_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bacc0c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T20:18:28.773990Z",
     "iopub.status.busy": "2022-02-09T20:18:28.748968Z",
     "iopub.status.idle": "2022-02-09T20:18:28.779109Z",
     "shell.execute_reply": "2022-02-09T20:18:28.778520Z",
     "shell.execute_reply.started": "2022-02-09T19:19:58.639877Z"
    },
    "papermill": {
     "duration": 0.041361,
     "end_time": "2022-02-09T20:18:28.779296",
     "exception": false,
     "start_time": "2022-02-09T20:18:28.737935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#The first step within any project of Machine Learning, is read, analyse and understand the datasets.\n",
    "#I can see that the columns called 'Age' and 'Cabin', have missing values (nan or empty), so we need to clean data or take decisions about the features for our model\n",
    "train_titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a230f70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T20:18:28.806411Z",
     "iopub.status.busy": "2022-02-09T20:18:28.805178Z",
     "iopub.status.idle": "2022-02-09T20:18:28.808299Z",
     "shell.execute_reply": "2022-02-09T20:18:28.807771Z",
     "shell.execute_reply.started": "2022-02-09T19:40:57.010241Z"
    },
    "papermill": {
     "duration": 0.020278,
     "end_time": "2022-02-09T20:18:28.808456",
     "exception": false,
     "start_time": "2022-02-09T20:18:28.788178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Let's split our data.\n",
    "#The prediction target is: 'Survived'\n",
    "y = train_titanic.Survived\n",
    "\n",
    "#We need to choose the feature data in order to train the model.\n",
    "feature_data = ['Pclass','Sex','Age','SibSp','Parch']\n",
    "X = train_titanic[feature_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffac7478",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T20:18:28.834621Z",
     "iopub.status.busy": "2022-02-09T20:18:28.833603Z",
     "iopub.status.idle": "2022-02-09T20:18:28.843703Z",
     "shell.execute_reply": "2022-02-09T20:18:28.842880Z",
     "shell.execute_reply.started": "2022-02-09T19:44:05.751973Z"
    },
    "papermill": {
     "duration": 0.026688,
     "end_time": "2022-02-09T20:18:28.843911",
     "exception": false,
     "start_time": "2022-02-09T20:18:28.817223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Pclass  891 non-null    int64  \n",
      " 1   Sex     891 non-null    object \n",
      " 2   Age     714 non-null    float64\n",
      " 3   SibSp   891 non-null    int64  \n",
      " 4   Parch   891 non-null    int64  \n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 34.9+ KB\n"
     ]
    }
   ],
   "source": [
    "#I'm going to search missing data, before i looked into all the data set with .info(), i realized that 'Survived' data are complete.\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f45c785",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T20:18:28.869262Z",
     "iopub.status.busy": "2022-02-09T20:18:28.868603Z",
     "iopub.status.idle": "2022-02-09T20:18:28.880870Z",
     "shell.execute_reply": "2022-02-09T20:18:28.880265Z",
     "shell.execute_reply.started": "2022-02-09T19:55:22.130726Z"
    },
    "papermill": {
     "duration": 0.027457,
     "end_time": "2022-02-09T20:18:28.881022",
     "exception": false,
     "start_time": "2022-02-09T20:18:28.853565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass     Sex  Age  SibSp  Parch\n",
      "5         3    male  NaN      0      0\n",
      "17        2    male  NaN      0      0\n",
      "19        3  female  NaN      0      0\n",
      "26        3    male  NaN      0      0\n",
      "28        3  female  NaN      0      0\n",
      "..      ...     ...  ...    ...    ...\n",
      "859       3    male  NaN      0      0\n",
      "863       3  female  NaN      8      2\n",
      "868       3    male  NaN      0      0\n",
      "878       3    male  NaN      0      0\n",
      "888       3  female  NaN      1      2\n",
      "\n",
      "[177 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#From the analysis before, we found that row 'Age' have some missing data, let's get rid of it\n",
    "print(X[X.isnull().values.any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07a80982",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T20:18:28.904756Z",
     "iopub.status.busy": "2022-02-09T20:18:28.904075Z",
     "iopub.status.idle": "2022-02-09T20:18:28.906847Z",
     "shell.execute_reply": "2022-02-09T20:18:28.906326Z"
    },
    "papermill": {
     "duration": 0.016363,
     "end_time": "2022-02-09T20:18:28.907023",
     "exception": false,
     "start_time": "2022-02-09T20:18:28.890660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#The total numbers of rows is: 891 and the number of rows with missing data is: 177, if we look at the .info() of the whole data, that number is consistent, that means we already know that the missing values are NaN.\n",
    "#We have two options, just eliminate all the rows with missing data or replace the NaN with some consistent data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.824964,
   "end_time": "2022-02-09T20:18:29.828297",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-09T20:18:18.003333",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
